{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng    250102\n",
      "spa    249898\n",
      "Name: Language, dtype: int64\n",
      "eng    2530\n",
      "spa    2471\n",
      "Name: Language, dtype: int64\n",
      "eng    5037\n",
      "spa    4964\n",
      "Name: Language, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "df = pd.read_csv('./lan_detection_data.csv') \n",
    "print(df['Language'].value_counts())\n",
    "\n",
    "df = pd.read_csv('./lan_detection_data_final.csv') \n",
    "df_train = df[0:500000]\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_validation = df.loc[500000:505000]\n",
    "df_validation = df_validation.reset_index(drop=True)\n",
    "df_test = df.loc[510000:520000]\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "# df.shape\n",
    "# df_validation.shape\n",
    "print(df_train['Language'].value_counts())\n",
    "print(df_validation['Language'].value_counts())\n",
    "print(df_test['Language'].value_counts())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import regexp_tokenize\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Here is a default pattern for tokenization, you can substitue it with yours\n",
    "default_pattern =  r\"\"\"(?x)                  \n",
    "                        (?:[A-Z]\\.)+          \n",
    "                        |\\$?\\d+(?:\\.\\d+)?%?    \n",
    "                        |\\w+(?:[-']\\w+)*      \n",
    "                        |\\.\\.\\.               \n",
    "                        |(?:[.,;\"'?():-_`])    \n",
    "                    \"\"\"\n",
    "\n",
    "def tokenize(text, pattern = default_pattern):\n",
    "    \"\"\"Tokenize senten with specific pattern\n",
    "    \n",
    "    Arguments:\n",
    "        text {str} -- sentence to be tokenized, such as \"I love NLP\"\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        pattern {str} -- reg-expression pattern for tokenizer (default: {default_pattern})\n",
    "    \n",
    "    Returns:\n",
    "        list -- list of tokenized words, such as ['I', 'love', 'nlp']\n",
    "    \"\"\"\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    return str(regexp_tokenize(text, pattern))\n",
    "\n",
    "\n",
    "class FeatureExtractor(object):\n",
    "    \"\"\"Base class for feature extraction.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, text_set):\n",
    "        pass\n",
    "    def transform(self, text):\n",
    "        pass  \n",
    "    def transform_list(self, text_set):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class UnigramFeature(FeatureExtractor):\n",
    "    \"\"\"Example code for unigram feature extraction\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # dictionary that maps unigrams into their indexes by order of appearance\n",
    "        self.unigram = {}\n",
    "        \n",
    "    def fit(self, text_set: list):\n",
    "        \"\"\"Fit a feature extractor based on given data \n",
    "        \n",
    "        Arguments:\n",
    "            text_set {list} -- list of tokenized sentences and words are lowercased, such as [[\"I\", \"love\", \"nlp\"], [\"I\", \"like\", \"python\"]]\n",
    "        \"\"\"\n",
    "        index = 0\n",
    "        for i in range(0, len(text_set)):\n",
    "            for j in range(0, len(text_set[i])):\n",
    "                if text_set[i][j].lower() not in self.unigram:\n",
    "                    self.unigram[text_set[i][j].lower()] = index\n",
    "                    index += 1\n",
    "                else:\n",
    "                    continue\n",
    "                    \n",
    "    def transform(self, text: list):\n",
    "        \"\"\"Transform a given sentence into vectors based on the extractor you got from self.fit()\n",
    "        \n",
    "        Arguments:\n",
    "            text {list} -- a tokenized sentence (list of words), such as [\"I\", \"love\", \"nlp\"]\n",
    "        \n",
    "        Returns:\n",
    "            array -- an unigram feature array, such as array([1,1,1,0,0,0])\n",
    "        \"\"\"\n",
    "        # Feature has the size of the number of distinct words received\n",
    "        feature = np.zeros(len(self.unigram))\n",
    "        # We go through every word in the text\n",
    "        for i in range(0, len(text)):\n",
    "            if text[i].lower() in self.unigram:\n",
    "                # If it contained in the unigram,\n",
    "                # It is a feature of the new text.\n",
    "                # We search for the index of the word in the text and use that index in the feature as well\n",
    "                # Then, we increase the number of occurrences of that word.\n",
    "                # Seems like the bag of words seen in class.\n",
    "                feature[self.unigram[text[i].lower()]] += 1\n",
    "        \n",
    "        return feature.tolist()\n",
    "    \n",
    "    \n",
    "    def transform_list(self, text_set: list):\n",
    "        \"\"\"Transform a list of tokenized sentences into vectors based on the extractor you got from self.fit()\n",
    "        \n",
    "        Arguments:\n",
    "            text_set {list} --a list of tokenized sentences, such as [[\"I\", \"love\", \"nlp\"], [\"I\", \"like\", \"python\"]]\n",
    "        \n",
    "        Returns:\n",
    "            array -- unigram feature arraies, such as array([[1,1,1,0,0], [1,0,0,1,1]])\n",
    "        \"\"\"\n",
    "        # Same as previous method but at sentences level\n",
    "        features = []\n",
    "        for i in range(0, len(text_set)):\n",
    "            features.append(self.transform(text_set[i]))\n",
    "        \n",
    "        \n",
    "        \n",
    "        return np.array(features)\n",
    "\n",
    "    def indexesToWords(self, words):\n",
    "        for word, index in self.unigram.items():\n",
    "            if index in words:\n",
    "                print(word)\n",
    "    \n",
    "    def save(self):\n",
    "        \"\"\"save class as self.name.txt\"\"\"\n",
    "        file = open('feature_extractor.txt','wb')\n",
    "        file.write(pickle.dumps(self.__dict__))\n",
    "        file.close()\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"try load self.name.txt\"\"\"\n",
    "        file = open('feature_extractor.txt','rb')\n",
    "        dataPickle = file.read()\n",
    "        file.close()\n",
    "\n",
    "        self.__dict__ = pickle.loads(dataPickle)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0  Unnamed: 0.1 Language  \\\n",
      "0         250633       6076601      eng   \n",
      "1        1053850       3255881      eng   \n",
      "2        1827548       7376708      eng   \n",
      "3        1900417       5567566      spa   \n",
      "4          30628       9080415      eng   \n",
      "...          ...           ...      ...   \n",
      "4996      652007        275002      eng   \n",
      "4997      804386       2888176      spa   \n",
      "4998     1039379       6231485      eng   \n",
      "4999       64252        864357      spa   \n",
      "5000     1378543       1853480      eng   \n",
      "\n",
      "                                                   Text  \\\n",
      "0                   Is anybody here willing to do that?   \n",
      "1     If it's a simple piece of music, I can sight-s...   \n",
      "2                  Mary is blind in one eye, isn't she?   \n",
      "3     Uno de mis favoritos cuentos de hadas cuando e...   \n",
      "4                                Let's go to the party!   \n",
      "...                                                 ...   \n",
      "4996                     He that talks much, errs much.   \n",
      "4997                    Mira esa torre sobre la colina.   \n",
      "4998  I told Tom I wanted him to teach me how to do ...   \n",
      "4999   Las mujeres tienden a vivir más que los hombres.   \n",
      "5000  The general theory of relativity explains the ...   \n",
      "\n",
      "                                                 tokens  labels  \\\n",
      "0     ['is', 'anybody', 'here', 'willing', 'to', 'do...       0   \n",
      "1     ['if', \"it's\", 'a', 'simple', 'piece', 'of', '...       0   \n",
      "2     ['mary', 'is', 'blind', 'in', 'one', 'eye', ',...       0   \n",
      "3     ['uno', 'de', 'mis', 'favoritos', 'cuentos', '...       1   \n",
      "4                 [\"let's\", 'go', 'to', 'the', 'party']       0   \n",
      "...                                                 ...     ...   \n",
      "4996  ['he', 'that', 'talks', 'much', ',', 'errs', '...       0   \n",
      "4997  ['mira', 'esa', 'torre', 'sobre', 'la', 'colin...       1   \n",
      "4998  ['i', 'told', 'tom', 'i', 'wanted', 'him', 'to...       0   \n",
      "4999  ['las', 'mujeres', 'tienden', 'a', 'vivir', 'm...       1   \n",
      "5000  ['the', 'general', 'theory', 'of', 'relativity...       0   \n",
      "\n",
      "                                                vectors  \n",
      "0     [1.0, 16.0, 2.0, 3.0, 1.0, 7.0, 7.0, 0.0, 2.0,...  \n",
      "1     [1.0, 25.0, 1.0, 9.0, 5.0, 13.0, 12.0, 2.0, 3....  \n",
      "2     [1.0, 19.0, 1.0, 4.0, 3.0, 10.0, 9.0, 0.0, 4.0...  \n",
      "3     [1.0, 44.0, 2.0, 9.0, 7.0, 22.0, 21.0, 1.0, 8....  \n",
      "4     [1.0, 9.0, 1.0, 0.0, 1.0, 4.0, 4.0, 1.0, 2.0, ...  \n",
      "...                                                 ...  \n",
      "4996  [1.0, 16.0, 4.0, 0.0, 2.0, 8.0, 7.0, 0.0, 2.0,...  \n",
      "4997  [1.0, 14.0, 0.0, 2.0, 2.0, 6.0, 6.0, 0.0, 3.0,...  \n",
      "4998  [1.0, 28.0, 4.0, 3.0, 0.0, 13.0, 13.0, 0.0, 3....  \n",
      "4999  [1.0, 20.0, 1.0, 3.0, 5.0, 9.0, 9.0, 0.0, 6.0,...  \n",
      "5000  [1.0, 30.0, 5.0, 6.0, 4.0, 14.0, 14.0, 4.0, 14...  \n",
      "\n",
      "[5001 rows x 7 columns]\n",
      "       Unnamed: 0  Unnamed: 0.1 Language  \\\n",
      "0         1781488       1719515      spa   \n",
      "1          772212         56151      eng   \n",
      "2         1820104       7325550      eng   \n",
      "3         1752794       3154681      eng   \n",
      "4         1445366       3394357      eng   \n",
      "...           ...           ...      ...   \n",
      "9996        66538       6142089      eng   \n",
      "9997      1373234       9496725      eng   \n",
      "9998      1528120       8826759      eng   \n",
      "9999      1668131       1574236      eng   \n",
      "10000     1038980       3417403      eng   \n",
      "\n",
      "                                                    Text  \\\n",
      "0                  Coloca el libro en su lugar anterior.   \n",
      "1                     This is the temple where he stays.   \n",
      "2                                  Sami made this video.   \n",
      "3                                  We haven't eaten yet.   \n",
      "4                     Everyone is saying goodbye to Tom.   \n",
      "...                                                  ...   \n",
      "9996                 He ordered one grilled fish dinner.   \n",
      "9997   Somebody has confessed to the crime that Tom i...   \n",
      "9998       His manner on the telephone was always short.   \n",
      "9999                         What newspaper do you read?   \n",
      "10000                          Tom is quite adventurous.   \n",
      "\n",
      "                                                  tokens  labels  \\\n",
      "0      ['coloca', 'el', 'libro', 'en', 'su', 'lugar',...       1   \n",
      "1      ['this', 'is', 'the', 'temple', 'where', 'he',...       0   \n",
      "2                 ['sami', 'made', 'this', 'video', '.']       0   \n",
      "3                 ['we', \"haven't\", 'eaten', 'yet', '.']       0   \n",
      "4      ['everyone', 'is', 'saying', 'goodbye', 'to', ...       0   \n",
      "...                                                  ...     ...   \n",
      "9996   ['he', 'ordered', 'one', 'grilled', 'fish', 'd...       0   \n",
      "9997   ['somebody', 'has', 'confessed', 'to', 'the', ...       0   \n",
      "9998   ['his', 'manner', 'on', 'the', 'telephone', 'w...       0   \n",
      "9999     ['what', 'newspaper', 'do', 'you', 'read', '?']       0   \n",
      "10000         ['tom', 'is', 'quite', 'adventurous', '.']       0   \n",
      "\n",
      "                                                 vectors  \n",
      "0      [1.0, 16.0, 0.0, 2.0, 1.0, 7.0, 7.0, 0.0, 3.0,...  \n",
      "1      [1.0, 16.0, 4.0, 2.0, 4.0, 7.0, 7.0, 1.0, 6.0,...  \n",
      "2      [1.0, 10.0, 1.0, 3.0, 2.0, 4.0, 4.0, 0.0, 2.0,...  \n",
      "3      [1.0, 9.0, 1.0, 0.0, 0.0, 4.0, 4.0, 0.0, 5.0, ...  \n",
      "4      [1.0, 14.0, 0.0, 2.0, 2.0, 6.0, 6.0, 0.0, 4.0,...  \n",
      "...                                                  ...  \n",
      "9996   [1.0, 14.0, 2.0, 3.0, 1.0, 6.0, 6.0, 0.0, 6.0,...  \n",
      "9997   [1.0, 26.0, 3.0, 4.0, 6.0, 12.0, 12.0, 1.0, 5....  \n",
      "9998   [1.0, 18.0, 4.0, 1.0, 4.0, 8.0, 8.0, 1.0, 5.0,...  \n",
      "9999   [1.0, 12.0, 1.0, 0.0, 1.0, 5.0, 5.0, 2.0, 3.0,...  \n",
      "10000  [1.0, 10.0, 0.0, 2.0, 2.0, 4.0, 4.0, 0.0, 2.0,...  \n",
      "\n",
      "[10001 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokens = []\n",
    "labels = []\n",
    "lan_to_label = {'eng':0,'spa':1}\n",
    "feature_extractor = UnigramFeature()\n",
    "\n",
    "\n",
    "# training data\n",
    "for row in df.index:\n",
    "    tokens.append(tokenize(df.loc[row]['Text']))\n",
    "    labels.append(lan_to_label[df.loc[row]['Language']])\n",
    "\n",
    "df['tokens'] = tokens\n",
    "df['labels'] = labels\n",
    "\n",
    "feature_extractor.fit(tokens)\n",
    "feature_extractor.save()\n",
    "\n",
    "feature_extractor.load()\n",
    "\n",
    "vectors = feature_extractor.transform_list(tokens)\n",
    "vectors = vectors.tolist()\n",
    "\n",
    "\n",
    "\n",
    "len(vectors)\n",
    "vectors = pd.Series(vectors)\n",
    "df['vectors'] = vectors\n",
    "\n",
    "# validation and test data\n",
    "tokens = []\n",
    "labels = []\n",
    "for row in df_validation.index:\n",
    "    tokens.append(tokenize(df_validation.loc[row]['Text']))\n",
    "    labels.append(lan_to_label[df_validation.loc[row]['Language']])\n",
    "\n",
    "df_validation['tokens'] = tokens\n",
    "df_validation['labels'] = labels\n",
    "vectors = feature_extractor.transform_list(tokens)\n",
    "vectors = vectors.tolist()\n",
    "vectors = pd.Series(vectors)\n",
    "df_validation['vectors'] = vectors\n",
    "\n",
    "tokens = []\n",
    "labels = []\n",
    "for row in df_test.index:\n",
    "    tokens.append(tokenize(df_test.loc[row]['Text']))\n",
    "    labels.append(lan_to_label[df_test.loc[row]['Language']])\n",
    "\n",
    "df_test['tokens'] = tokens\n",
    "df_test['labels'] = labels\n",
    "vectors = feature_extractor.transform_list(tokens)\n",
    "vectors = vectors.tolist()\n",
    "vectors = pd.Series(vectors)\n",
    "df_test['vectors'] = vectors\n",
    "\n",
    "\n",
    "print(df_validation)\n",
    "print(df_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'[': 0, \"'\": 1, 'h': 2, 'i': 3, 's': 4, ',': 5, ' ': 6, 'p': 7, 'e': 8, 'c': 9, 'a': 10, 'd': 11, 'n': 12, 'f': 13, 't': 14, 'o': 15, 'u': 16, 'r': 17, 'm': 18, '.': 19, ']': 20, 'y': 21, 'k': 22, 'w': 23, '\"': 24, 'l': 25, 'x': 26, 'g': 27, 'v': 28, 'b': 29, 'z': 30, '?': 31, 'q': 32, 'ó': 33, 'j': 34, 'á': 35, 'é': 36, '6': 37, 'í': 38, '1': 39, '9': 40, '7': 41, '4': 42, '8': 43, 'ú': 44, '2': 45, '0': 46, '-': 47, '3': 48, 'ñ': 49, ':': 50, 'æ': 51, ';': 52, '(': 53, ')': 54, '%': 55, '5': 56, 'ü': 57, '$': 58, 'ṛ': 59, 'ḥ': 60, 'ɣ': 61, 'ṭ': 62, 'ø': 63, 'ẓ': 64, 'ḍ': 65, 'ö': 66, 'ɛ': 67, 'ē': 68, 'ǧ': 69, 'è': 70, '이': 71, '것': 72, '은': 73, '사': 74, '전': 75, '다': 76, '그': 77, '건': 78, '내': 79, '야': 80, 'ë': 81, '누': 82, '구': 83, '입': 84, '니': 85, '까': 86, '비': 87, '싸': 88, '면': 89, '될': 90, '요': 91, '는': 92, '을': 93, '용': 94, '했': 95, '나': 96, '에': 97, '게': 98, '있': 99, 'त': 100, 'ल': 101, 'आ': 102, 'व': 103, 'ड': 104, 'स': 105, 'म': 106, 'ह': 107, 'à': 108, '당': 109, '신': 110, '의': 111, 'य': 112, 'न': 113, 'ā': 114, 'ǎ': 115, '_': 116, 'ï': 117, 'ç': 118, 'ã': 119, 'ṅ': 120, 'п': 121, 'р': 122, 'е': 123, 'д': 124, 'л': 125, 'о': 126, 'ж': 127, 'н': 128, 'и': 129, 'у': 130, 'ч': 131, 'с': 132, 'ь': 133, 'в': 134, 'м': 135, 'ы': 136, 'э': 137, 'т': 138, 'к': 139, 'а': 140, 'ю': 141, 'з': 142, 'б': 143, 'ш': 144, 'й': 145, '>': 146, 'č': 147, 'ê': 148, 'ο': 149, 'â': 150, '=': 151, 'ä': 152, 'ċ': 153, '₂': 154, 'ń': 155, 'ł': 156, 'º': 157, 'ß': 158, 'ð': 159, 'ı': 160, 'ʻ': 161, 'š': 162, 'ウ': 163, 'エ': 164, 'ー': 165, 'ト': 166, 'レ': 167, 'ス': 168, 'ę': 169, 'ć': 170, 'ō': 171, 'õ': 172, 'å': 173, 'ŝ': 174, 'ứ': 175, 'ﷺ': 176, 'π': 177, 'あ': 178, 'δ': 179, '^': 180, 'μ': 181, 'ź': 182, 'ŭ': 183, 'î': 184, 'प': 185, 'ʽ': 186, 'ω': 187, 'ī': 188, 'ò': 189, '@': 190, 'θ': 191, 'ū': 192, 'ż': 193, 'ε': 194, 'ş': 195, '²': 196, 'ì': 197, 'γ': 198, '`': 199, 'ṃ': 200, 'г': 201, 'я': 202, 'щ': 203, 'ц': 204, 'х': 205, 'ф': 206, 'ё': 207, 'є': 208, 'ї': 209, '<': 210, '³': 211, 'ѝ': 212, 'ș': 213, 'ă': 214, 'ĺ': 215, 'ņ': 216, 'ǔ': 217, '⁰': 218, '¹': 219}\n"
     ]
    }
   ],
   "source": [
    "print(feature_extractor.unigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n",
      "500001 500001\n",
      "5001 5001\n",
      "10001 10001\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x_train = torch.tensor(df['vectors'])\n",
    "y_train = torch.tensor(df['labels'],dtype=torch.float32)\n",
    "\n",
    "x_validation = torch.tensor(df_validation['vectors'])\n",
    "y_validation = torch.tensor(df_validation['labels'],dtype=torch.float32)\n",
    "\n",
    "x_test = torch.tensor(df_test['vectors'])\n",
    "y_test = torch.tensor(df_test['labels'],dtype=torch.float32)\n",
    "\n",
    "print(x_train.dtype)\n",
    "print(y_train.dtype)\n",
    "print(len(x_train),len(y_train))\n",
    "print(len(x_validation),len(y_validation))\n",
    "print(len(x_test),len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "validation_ds = TensorDataset(x_validation, y_validation)\n",
    "test_ds = TensorDataset(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 16\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "validation_dl = DataLoader(validation_ds, batch_size, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ClassificationModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size,embedding_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        print(vocab_size)\n",
    "        self.embedded_layer = nn.Embedding(vocab_size,embedding_dim=embedding_dim)\n",
    "        self.fc1 = torch.nn.Linear(vocab_size, hidden_dim)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim,32)\n",
    "        self.fc3 = torch.nn.Linear(32,1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.fc1(x)        \n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        output = self.sigmoid(x)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1., 18.,  3.,  ...,  0.,  0.,  0.],\n",
      "        [ 1., 31.,  4.,  ...,  0.,  0.,  0.],\n",
      "        [ 1., 15.,  2.,  ...,  0.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 1., 12.,  1.,  ...,  0.,  0.,  0.],\n",
      "        [ 1., 22.,  2.,  ...,  0.,  0.,  0.],\n",
      "        [ 1., 22.,  2.,  ...,  0.,  0.,  0.]])\n",
      "220\n"
     ]
    }
   ],
   "source": [
    "hidden_dimension = 64\n",
    "embedding_dimension = 300\n",
    "print(x_train)\n",
    "vocab_dimension = len(x_train[0])\n",
    "model = ClassificationModel(vocab_dimension, embedding_dimension, hidden_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "learning_rate = 0.0001\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "opt = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to train the model\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import tqdm\n",
    "def train(model, loss_fn, opt, train_dl):\n",
    "    model.train()\n",
    "    true, preds = [], []\n",
    "    total_loss = 0\n",
    "    # Repeat for given number of epochs\n",
    "\n",
    "        \n",
    "    # Train with batches of data\n",
    "    for xb,yb in tqdm.tqdm(train_dl):\n",
    "        \n",
    "        # 1. Generate predictions\n",
    "        pred = model(xb)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 2. Calculate loss\n",
    "        \n",
    "        pred = torch.squeeze(pred)\n",
    "        yb = torch.squeeze(yb)\n",
    "        loss = loss_fn(pred, yb)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "\n",
    "\n",
    "        # # saving the results\n",
    "        # for i_batch in range(len(yb)):\n",
    "        #     true.append(yb[i_batch].item())\n",
    "        #     preds.append(round(pred[i_batch].item()))\n",
    "        \n",
    "        # 3. Compute gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # 4. Update parameters using gradients\n",
    "        opt.step()\n",
    "        \n",
    "        # 5. Reset the gradients to zero\n",
    "        opt.zero_grad()\n",
    "\n",
    "    # Print the progress\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to train the model\n",
    "def test(model, loss_fn, validation_dl):\n",
    "    true, preds = [], []\n",
    "    total_loss = 0\n",
    "    # Train with batches of data\n",
    "    for xb,yb in tqdm.tqdm(validation_dl):\n",
    "        \n",
    "        # 1. Generate predictions\n",
    "        pred = model(xb)\n",
    "\n",
    "        # saving the results\n",
    "        # for i_batch in range(len(yb)):\n",
    "        #     true.append(yb[i_batch].item())\n",
    "        #     preds.append(round(pred[i_batch].item()))\n",
    "       \n",
    "        pred = torch.squeeze(pred)\n",
    "        yb = torch.squeeze(yb)\n",
    "        \n",
    "        # 2. Calculate loss\n",
    "        loss = loss_fn(pred, yb)\n",
    "        total_loss += loss.item()\n",
    "    return true, preds, total_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31251/31251 [00:21<00:00, 1482.17it/s]\n",
      "100%|██████████| 31251/31251 [00:10<00:00, 2888.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31251/31251 [00:22<00:00, 1386.67it/s]\n",
      "100%|██████████| 31251/31251 [00:10<00:00, 2862.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 11907/31251 [00:08<00:13, 1428.69it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9188/737961282.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mTOTAL_EPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTOTAL_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mv_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtrain_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_9188/1141141306.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loss_fn, opt, train_dl)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Train with batches of data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# 1. Generate predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_store = []\n",
    "validation_store = []\n",
    "acc_train_store = []\n",
    "acc_val_store = []\n",
    "f1_train_store = []\n",
    "f1_val_store = []\n",
    "TOTAL_EPOCHS = 10\n",
    "for epoch in range(TOTAL_EPOCHS):\n",
    "    train_loss = train(model, loss_fn, opt,train_dl)\n",
    "    v_true, v_pred, val_loss = test(model,loss_fn, validation_dl)\n",
    "    train_store.append(train_loss)\n",
    "\n",
    "    # validation_store.append(val_loss)\n",
    "    print(f\"EPOCH: {epoch}\")\n",
    "    \"\"\"\n",
    "    print(f\"TRAIN LOSS: {train_loss}\")\n",
    "    print(f\"VALIDATION LOSS: {val_loss}\")\n",
    "\n",
    "    acc_val = accuracy_score(v_true, v_pred)\n",
    "    f1_val = f1_score(v_true, v_pred, average='weighted')\n",
    "    # acc_train = accuracy_score(t_true, t_pred)\n",
    "    # f1_train = f1_score(t_true, t_pred, average='weighted')\n",
    "\n",
    "    acc_val_store.append(acc_val)\n",
    "    f1_val_store.append(f1_val)\n",
    "    # acc_train_store.append(acc_train)\n",
    "    # f1_train_store.append(f1_train)\n",
    "\n",
    "    print(f\"VAL F-1: {f1_val}\")\n",
    "    print(f\"VAL ACC: {acc_val}\")\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_store, c=\"red\", label =\"train\")\n",
    "plt.plot(validation_store, c=\"blue\", label =\"validation\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(acc_train_store, c=\"red\", label =\"train\")\n",
    "plt.plot(acc_val_store, c=\"blue\", label =\"validation\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(f1_train_store, c=\"red\", label =\"train\")\n",
    "plt.plot(f1_val_store, c=\"blue\", label =\"validation\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 18555/31251 [00:09<00:06, 1953.24it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7050/4261257979.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"VAL F-1: {f1_score(true, pred, average='weighted')}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"VAL ACC: {accuracy_score(true, pred)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_7050/2812554412.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, loss_fn, dataloader)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mtrue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "true, pred, val_loss = test(model,loss_fn, test_dl)\n",
    "print(f\"VAL F-1: {f1_score(true, pred, average='weighted')}\")\n",
    "print(f\"VAL ACC: {accuracy_score(true, pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './model_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import regexp_tokenize\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "# Here is a default pattern for tokenization, you can substitue it with yours\n",
    "default_pattern =  r\"\"\"(?x)                  \n",
    "                        (?:[A-Z]\\.)+          \n",
    "                        |\\$?\\d+(?:\\.\\d+)?%?    \n",
    "                        |\\w+(?:[-']\\w+)*      \n",
    "                        |\\.\\.\\.               \n",
    "                        |(?:[.,;\"'?():-_`])    \n",
    "                    \"\"\"\n",
    "\n",
    "def tokenize(text, pattern = default_pattern):\n",
    "    \"\"\"Tokenize senten with specific pattern\n",
    "    \n",
    "    Arguments:\n",
    "        text {str} -- sentence to be tokenized, such as \"I love NLP\"\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        pattern {str} -- reg-expression pattern for tokenizer (default: {default_pattern})\n",
    "    \n",
    "    Returns:\n",
    "        list -- list of tokenized words, such as ['I', 'love', 'nlp']\n",
    "    \"\"\"\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    return str(regexp_tokenize(text, pattern))\n",
    "\n",
    "\n",
    "class FeatureExtractor(object):\n",
    "    \"\"\"Base class for feature extraction.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, text_set):\n",
    "        pass\n",
    "    def transform(self, text):\n",
    "        pass  \n",
    "    def transform_list(self, text_set):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class UnigramFeature(FeatureExtractor):\n",
    "    \"\"\"Example code for unigram feature extraction\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # dictionary that maps unigrams into their indexes by order of appearance\n",
    "        self.unigram = {}\n",
    "        \n",
    "    def fit(self, text_set: list):\n",
    "        \"\"\"Fit a feature extractor based on given data \n",
    "        \n",
    "        Arguments:\n",
    "            text_set {list} -- list of tokenized sentences and words are lowercased, such as [[\"I\", \"love\", \"nlp\"], [\"I\", \"like\", \"python\"]]\n",
    "        \"\"\"\n",
    "        index = 0\n",
    "        for i in range(0, len(text_set)):\n",
    "            for j in range(0, len(text_set[i])):\n",
    "                if text_set[i][j].lower() not in self.unigram:\n",
    "                    self.unigram[text_set[i][j].lower()] = index\n",
    "                    index += 1\n",
    "                else:\n",
    "                    continue\n",
    "                    \n",
    "    def transform(self, text: list):\n",
    "        \"\"\"Transform a given sentence into vectors based on the extractor you got from self.fit()\n",
    "        \n",
    "        Arguments:\n",
    "            text {list} -- a tokenized sentence (list of words), such as [\"I\", \"love\", \"nlp\"]\n",
    "        \n",
    "        Returns:\n",
    "            array -- an unigram feature array, such as array([1,1,1,0,0,0])\n",
    "        \"\"\"\n",
    "        # Feature has the size of the number of distinct words received\n",
    "        feature = np.zeros(len(self.unigram))\n",
    "        # We go through every word in the text\n",
    "        for i in range(0, len(text)):\n",
    "            if text[i].lower() in self.unigram:\n",
    "                # If it contained in the unigram,\n",
    "                # It is a feature of the new text.\n",
    "                # We search for the index of the word in the text and use that index in the feature as well\n",
    "                # Then, we increase the number of occurrences of that word.\n",
    "                # Seems like the bag of words seen in class.\n",
    "                feature[self.unigram[text[i].lower()]] += 1\n",
    "        \n",
    "        return feature.tolist()\n",
    "    \n",
    "    \n",
    "    def transform_list(self, text_set: list):\n",
    "        \"\"\"Transform a list of tokenized sentences into vectors based on the extractor you got from self.fit()\n",
    "        \n",
    "        Arguments:\n",
    "            text_set {list} --a list of tokenized sentences, such as [[\"I\", \"love\", \"nlp\"], [\"I\", \"like\", \"python\"]]\n",
    "        \n",
    "        Returns:\n",
    "            array -- unigram feature arraies, such as array([[1,1,1,0,0], [1,0,0,1,1]])\n",
    "        \"\"\"\n",
    "        # Same as previous method but at sentences level\n",
    "        features = []\n",
    "        for i in range(0, len(text_set)):\n",
    "            features.append(self.transform(text_set[i]))\n",
    "        \n",
    "        \n",
    "        \n",
    "        return np.array(features)\n",
    "\n",
    "    def indexesToWords(self, words):\n",
    "        for word, index in self.unigram.items():\n",
    "            if index in words:\n",
    "                print(word)\n",
    "    \n",
    "    def save(self):\n",
    "        \"\"\"save class as self.name.txt\"\"\"\n",
    "        file = open('feature_extractor.txt','wb')\n",
    "        file.write(pickle.dumps(self.__dict__))\n",
    "        file.close()\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"try load self.name.txt\"\"\"\n",
    "        file = open('feature_extractor.txt','rb')\n",
    "        dataPickle = file.read()\n",
    "        file.close()\n",
    "\n",
    "        self.__dict__ = pickle.loads(dataPickle)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cuál', 'es', 'el', 'mejor', 'restaurante', 'de', 'nueva', 'york', '?']\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = UnigramFeature()\n",
    "feature_extractor.load()\n",
    "\n",
    "query = \"Cuál es el mejor restaurante de Nueva York?\"\n",
    "query = tokenize(query)\n",
    "print(query)\n",
    "\n",
    "query = feature_extractor.transform(query)\n",
    "query = torch.tensor(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ClassificationModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, hidden_dim):\n",
    "        super().__init__()\n",
    "        print(vocab_size)\n",
    "        self.embedded_layer = nn.Embedding(vocab_size,embedding_dim=embedding_dim)\n",
    "        self.fc1 = torch.nn.Linear(vocab_size, hidden_dim)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim,32)\n",
    "        self.fc3 = torch.nn.Linear(32,1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.fc1(x)        \n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        output = self.sigmoid(x)\n",
    "                \n",
    "        return output\n",
    "model = ClassificationModel(len(query),64)\n",
    "model.load_state_dict(torch.load('./model_file'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "es\n"
     ]
    }
   ],
   "source": [
    "def predict(model, query):\n",
    "    model.zero_grad()    \n",
    "    result = model(query)\n",
    "    result = round(result.item())\n",
    "    if result == 0:\n",
    "        print('en')\n",
    "    else:\n",
    "        print('es')\n",
    "\n",
    "\n",
    "predict(model,query)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8abf625e542ff33194dd4502f291ce11b7bf8daed732e6d5f31b5a030b27ce17"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
