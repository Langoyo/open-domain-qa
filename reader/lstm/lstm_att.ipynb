{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10251,"status":"ok","timestamp":1661008320994,"user":{"displayName":"Andrés Langoyo Martín","userId":"12914381003507187562"},"user_tz":-120},"id":"r6gv7djVH7p5","outputId":"037cbdb2-d29e-48af-97a4-e7c26be94102"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n","\u001b[K     |████████████████████████████████| 365 kB 7.1 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.7.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n","\u001b[K     |████████████████████████████████| 115 kB 73.5 MB/s \n","\u001b[?25hCollecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Collecting huggingface-hub<1.0.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 8.0 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)\n","Collecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 35.2 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.8.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 72.5 MB/s \n","\u001b[?25hRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.2.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: urllib3, xxhash, responses, multiprocess, huggingface-hub, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed datasets-2.4.0 huggingface-hub-0.8.1 multiprocess-0.70.13 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0\n"]}],"source":["!pip install datasets"],"id":"r6gv7djVH7p5"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1661008320995,"user":{"displayName":"Andrés Langoyo Martín","userId":"12914381003507187562"},"user_tz":-120},"id":"JP84uzB6p2rH","outputId":"8adb18f9-3478-480e-83ea-c099879c6831"},"outputs":[{"data":{"application/javascript":["function ClickConnect(){\n","console.log(\"Working\");\n","document.querySelector(\"colab-toolbar-button#connect\").click()\n","}setInterval(ClickConnect,60000)\n"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["%%javascript\n","function ClickConnect(){\n","console.log(\"Working\");\n","document.querySelector(\"colab-toolbar-button#connect\").click()\n","}setInterval(ClickConnect,60000)"],"id":"JP84uzB6p2rH"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17,"referenced_widgets":["14b1614325784435a3d92346abf9a732","c81ef08e3255462796d628a7b4353fd5","4e66d7661f094e5b93c63896f767e6eb","67fe51f221994db5bf850e6d00078dab","c2407428f34d4af0a2e65cd2836e1add","d56fcbc1046249cbb84963a241491232","fa9d8a79d15a483881a8c16ab6edb32d","c59f461d2bf1483997e7e30354651810","45710764b4354e27a12cae622a68e660","8e99850fc8f24225bc0837e31eb427a7","59ca87c8533d4999962fab467057d16a","dbe44fde2789492686680796ed70a311","eb901f9492834794a87869183e8d7b3d","112db4ff649d4754b6294c92a0139b5a","5de5081627914f06bcf4a09459fbff97","85a555b973e14d6eb928a73e90905bb0","34aa7831b12647919744d4cf3e9114bd","90d8307121164fddb2a3742e43d0acd2","61df97bc3f424116b65267dec26025a3","c9505fe6cd6749c78d3ffd19a229085c","2d63d6d48d9f48e4947ec386468c0b7c","b1c428dbd7f14c94bf890b73c7b051ad"]},"executionInfo":{"elapsed":2881,"status":"ok","timestamp":1661008323850,"user":{"displayName":"Andrés Langoyo Martín","userId":"12914381003507187562"},"user_tz":-120},"id":"363ac1d3","outputId":"1948255e-a829-4a95-ac3a-20cdde027187"},"outputs":[{"data":{"application/json":{"ascii":false,"bar_format":null,"colour":null,"elapsed":0.019371747970581055,"initial":0,"n":0,"ncols":null,"nrows":null,"postfix":null,"prefix":"Downloading builder script","rate":null,"total":1715,"unit":"B","unit_divisor":1000,"unit_scale":true},"application/vnd.jupyter.widget-view+json":{"model_id":"14b1614325784435a3d92346abf9a732","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/json":{"ascii":false,"bar_format":null,"colour":null,"elapsed":0.017728567123413086,"initial":0,"n":0,"ncols":null,"nrows":null,"postfix":null,"prefix":"Downloading extra modules","rate":null,"total":1119,"unit":"B","unit_divisor":1000,"unit_scale":true},"application/vnd.jupyter.widget-view+json":{"model_id":"dbe44fde2789492686680796ed70a311","version_major":2,"version_minor":0},"text/plain":["Downloading extra modules:   0%|          | 0.00/1.12k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["import torch\n","from datasets import load_dataset, load_metric\n","squad_metric = load_metric('squad')\n","import math"],"id":"363ac1d3"},{"cell_type":"code","execution_count":null,"metadata":{"id":"55ba9f57"},"outputs":[],"source":["def preprocess(example):\n","    # This class preprocesses an example of the Squad dataset so that it works with word tokens\n","    \n","    # Data structure to be returned\n","    out = {}\n","\n","    # The context and the question are tokenized by spaces.\n","    context_token = example['context'].strip().split(' ')\n","    question_token = example['question'].strip().split(' ')\n","    \n","    # We store in the data structure the tokens from the context and the questions\n","    out['context'] = context_token\n","    out['question'] = question_token\n","    \n","    if 'answers' not in example:\n","        return out\n","    \n","    # Now we search for the answers\n","    answer_start = example['answers']['answer_start']\n","    out['answers'] = []\n","    \n","    # And we calculate the start and end tokens of the answer\n","    for i, ans_st in enumerate(answer_start):\n","        c_token_len = len(example['context'][:ans_st].strip().split(' ')) # First we calculate the number of tokens until the answer start # strip removes leading/treading empty chars\n","        a_token_len = len(example['answers']['text'][i].strip().split(' ')) # Then we calculate the number of tokens in the answer\n","        out['answers'].append({'start' : c_token_len, 'end' : c_token_len + a_token_len})\n","    \n","    return out\n","\n","# tokenizing conext with space and symbolic letter.\n","def tokenizing1(text):\n","    text = text.lower()\n","    tokens = []\n","    tokens_start = []\n","    tokens_len = []\n","    where_space = []\n","    i, token_start, token_len = 0, 0, 0\n","    \n","    while i < len(text):\n","        # is character alphbet?\n","        if text[i].isalpha(): # alphabet\n","            # Searching for the token length\n","            while True:\n","                # We search fot the end of the token to end the loop\n","                token_len += 1\n","                if i + token_len >= len(text) or not text[i + token_len].isalpha():\n","                    break\n","            # We keep track of the token, its lenght and the start\n","            tokens.append(text[i:i+token_len])\n","            tokens_len.append(token_len)\n","            tokens_start.append(i)\n","            i += token_len\n","            token_len = 0\n","        elif text[i] == ' ': # space\n","            where_space.append(i)\n","            i += 1\n","        else: # symbolic char\n","            # with a symbolic char we simply add it to the tokens being length 1\n","            tokens.append(text[i])\n","            tokens_len.append(1)\n","            tokens_start.append(i)\n","            i += 1\n","    # Returns the word tokens, where they start, their length and where there are spaces\n","    return tokens, tokens_start, tokens_len, where_space\n","\n","def advanced_preprocess1(data):\n","    # calculates data structure with tokens their starts, lengths and the answer start and end\n","    \n","    out = {}\n","    # we tokenize context and answer\n","    tokens, tokens_start, tokens_len, where_space = tokenizing1(data['context'])\n","    tokens_q, _, _, _ = tokenizing1(data['question'])\n","    \n","    answer_start = data['answers']['answer_start']\n","    \n","    out = {'context' : tokens, 'question' : tokens_q, 'tokens_start' : tokens_start, 'tokens_len' : tokens_len, 'where_space' : where_space}\n","    \n","    out['answers'] = []\n","    \n","    for i, ans in enumerate(answer_start):\n","        start_index = tokens_start.index(ans)\n","        tokens, _, _, _ = tokenizing1(data['answers']['text'][i])\n","        end_index = start_index + len(tokens)\n","        out['answers'].append({'start' : start_index, 'end' : end_index})\n","    return out\n","\n","def token2string(context, tokens_start, tokens_len, tokens_answers, where_space, test = []):\n","    # Converts list of tokens into string\n","    \n","    cont = ''\n","\n","    for i, token in enumerate(context):\n","        # calculates forst the context\n","        if tokens_start[i] + tokens_len[i] in where_space:\n","            cont += (token + ' ')\n","        else:\n","            cont += token\n","    \n","    # calculating answer\n","    if len(test) > 0 :\n","            start_index = tokens_start[test[0]] if test[0] < len(context) else tokens_start[-1]\n","            end_index = tokens_start[test[1]] if test[1] < len(context) else tokens_start[-1]\n","    else:\n","        try:\n","            tokens_answers_start = tokens_answers['start']\n","            tokens_answers_end = tokens_answers['end']\n","            start_index = tokens_start[tokens_answers_start]\n","            end_index = tokens_start[tokens_answers_end-1] + tokens_len[tokens_answers_end -1]\n","        except:\n","             pass\n","    \n","    ans = cont[start_index : end_index]\n","    return cont, ans\n"],"id":"55ba9f57"},{"cell_type":"code","execution_count":null,"metadata":{"id":"32195cff"},"outputs":[],"source":["\n","def preprocessing(squad_dataset):\n","\ttrain_data = []\n","\tdel_train_data_index = []\n","\tcount = 0\n","    #preprocessing every example in the squad datset\n","\tfor i, data in enumerate(squad_dataset['train']):\n","\t\ttry:\n","\t\t\ttrain_data.append(advanced_preprocess1(data))\n","\t\texcept:\n","\t\t\ttrain_data.append([])\n","\t\t\tdel_train_data_index.append(i)\n","\t\t\tcount+=1\n","\t        \n","\n","\tvalid_data = []\n","\tdel_valid_data_index = []\n","\tcount = 0\n","\tfor i, data in enumerate(squad_dataset['validation']):\n","\t\ttry:\n","\t\t\tvalid_data.append(advanced_preprocess1(data))\n","\t\texcept:\n","\t\t\tvalid_data.append([])\n","\t\t\tdel_valid_data_index.append(i)\n","\t\t\tcount += 1\n","\n","\treturn train_data, del_train_data_index, valid_data, del_valid_data_index\n","\t\n"],"id":"32195cff"},{"cell_type":"code","execution_count":null,"metadata":{"id":"NF7nHIcBHkmE"},"outputs":[],"source":["\n","import torch\n","import torch.nn as nn\n","import numpy as np\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# word2id, id2word\n","\n","def make_dict(train_data, del_train_data_index):\n","\n","    # create a dictionary of word indexes\n","    word2id = {}\n","    tokens = []\n","    del_idx = []\n","    for i in range(len(train_data)):\n","        # skip if the example is invalid\n","        if i in del_train_data_index:\n","            continue\n","        # creating a list of tokens\n","        context_tokens = train_data[i]['context']\n","        question_tokens = train_data[i]['question']\n","        tokens.extend(context_tokens)\n","        tokens.extend(question_tokens)\n","        if not train_data[i]['answers']:\n","            del_idx.extend([i])\n","    # creating vocabulary\n","    vocab = ['UNK'] + list(set(tokens))\n","\t    \n","    # dictionaries for conversion\n","    word2id = {word : id_ for id_ , word in enumerate(vocab)}\n","    id2word = {id_ : word for word, id_ in word2id.items()}\n","\n","    return word2id, id2word\n","\n","def wordToid(data):\n","    # converts strign tokens into indexes\n","    context = data['context']\n","    question = data['question']\n","    \n","    context = [word2id[word] if word in word2id else 0 for word in context]\n","    question = [word2id[word] if word in word2id else 0 for word in question]\n","    \n","    answer = []\n","    \n","    for dic in data['answers']:\n","        start = dic['start']\n","        end = dic['end']\n","        answer.append(context[start:end])\n","    return context, question, answer\n","\n","\n","\n","def valid_answers(data_index, index = []):\n","    data = valid_data[data_index]\n","    context = data['context']\n","    tokens_start = data['tokens_start']\n","    tokens_len = data['tokens_len']\n","    where_space = data['where_space']\n","    \n","    if index[-1] > len(context):\n","        index[-1] = len(context)\n","    \n","    ans_tokens = context[index[0]:index[1]]\n","\n","    ans = ''\n","    for i, token in enumerate(ans_tokens):\n","        if tokens_start[index[0] + i] + tokens_len[index[0] + i] in where_space:\n","            ans += (token + ' ')\n","        else:\n","            ans += token\n","    \n","    return ans.strip().lower()\n","    \n","def id2word_answer(data_index, start, end):\n","    ### valid \n","    \n","    data = valid_data[data_index] \n","    origin_data = squad_dataset['validation'][data_index]\n","    \n","    ans = valid_answers(data_index, [start,end])\n","    \n","    for i, a in enumerate(origin_data['answers']['text']):\n","        origin_data['answers']['text'][i] = a.lower()\n","    \n","    prediction_ = {'prediction_text': ans, 'id': origin_data['id']}\n","    reference = {'answers' : origin_data['answers'], 'id': origin_data['id']}\n","    \n","    return prediction_, reference\n"],"id":"NF7nHIcBHkmE"},{"cell_type":"code","execution_count":null,"metadata":{"id":"96805ff9"},"outputs":[],"source":["# make batch . \n","\n","import numpy as np\n","import random\n","import torch\n","import torch.nn.functional as F\n","\n","def make_batch(data, batch_size = 64, index = [], random = True, question = True):\n","    data = np.array(data)\n","    if random:\n","        indice = np.random.choice(len(data), batch_size, replace = False)\n","        for i, idx in enumerate(indice):\n","            if idx in del_train_data_index:\n","                indice[i] = 0\n","        data_batch = data[indice]\n","        \n","    else:\n","        for i,idx in enumerate(index):\n","            if idx in del_valid_data_index:\n","                index[i] = 0\n","        data_batch = data[index]\n","\n","    context_max_len = 0\n","    question_max_len = 0\n","    \n","    for i in range(batch_size):\n","        if question:\n","            context_max_len = max(context_max_len, len(data_batch[i]['context']) + len(data_batch[i]['question']))\n","        else:\n","            context_max_len = max(context_max_len, len(data_batch[i]['context']))\n","    \n","    context_batch = []\n","    answer_start_batch = []\n","    answer_end_batch = []\n","    context_mask = []\n","    mask_loc = []\n","    \n","    for i, d in enumerate(data_batch):\n","        if d == []:\n","            continue\n","            \n","        context, questions, answer = wordToid(d)\n","        \n","        if question:\n","            context = np.concatenate([context, questions])\n","        \n","        context_len = len(context)\n","        context_padding = np.zeros(context_max_len - len(context))\n","        context = np.concatenate([context, context_padding])\n","        context_batch.append(context)\n","        \n","        for answers in data_batch[i]['answers']:\n","            answer_start_batch.append(answers['start'])\n","            answer_end_batch.append(answers['end'])\n","        \n","        context_mask.append(np.concatenate([np.ones(context_len), np.zeros(len(context_padding))], axis = 0))\n","        mask_loc.append(context_len)\n","\n","    # print(len(torch.LongTensor(context_batch)),len(torch.LongTensor(answer_start_batch)),len(torch.LongTensor(answer_end_batch)),len(torch.LongTensor(context_mask)),len(torch.LongTensor(mask_loc)))\n","        \n","    return torch.LongTensor(context_batch), torch.LongTensor(answer_start_batch), torch.LongTensor(answer_end_batch), torch.LongTensor(context_mask), torch.LongTensor(mask_loc)"],"id":"96805ff9"},{"cell_type":"code","execution_count":null,"metadata":{"id":"6d16aef2"},"outputs":[],"source":["class Attention(nn.Module):\n","    def __init__(self, embed_dim, num_heads = 4, dropout = 0.2, bias = True):\n","        super(Attention, self).__init__()\n","        \n","        self.embed_dim = embed_dim\n","        self.num_heads = num_heads \n","        self.dropout = dropout\n","        self.bias = bias\n","        self.head_dim = embed_dim // num_heads\n","        \n","        self.k_proj = nn.Linear(embed_dim, embed_dim, bias = bias)\n","        self.q_proj = nn.Linear(embed_dim, embed_dim, bias = bias)\n","        self.v_proj = nn.Linear(embed_dim, embed_dim, bias = bias)\n","        self.out_proj = nn.Linear(embed_dim, embed_dim, bias = bias)\n","        self.softmax = nn.Softmax(dim = -1)\n","    \n","    def scaled_dot_product(self, q, k, v, mask = None):\n","        # batch * seq * seq\n","        attention_weight = torch.matmul(q, k.transpose(-1,-2)) / math.sqrt(self.embed_dim)\n","        \n","        if mask is not None:\n","            attention_weight = attention_weight.masked_fill(mask == 0, -1e9)\n","        \n","        attention_weight = self.softmax(attention_weight)\n","        \n","        # batch * seq * embed_dim\n","        attention_output = torch.matmul(attention_weight, v)\n","        attention_output = self.out_proj(attention_output)\n","        \n","        return attention_output, attention_weight\n","    \n","    def forward(self, hidden, mask):\n","        query = self.q_proj(hidden) # batch * seq_len * hidden_dim(num_head * head_dim)\n","        key = self.k_proj(hidden) # batch * seq_len * hidden_dim(num_head * head_dim)\n","        value = self.v_proj(hidden) # batch * seq_len * hidden_dim(num_head * head_dim)\n","        \n","        \n","        \n","        attn_output, attn_weight = self.scaled_dot_product(query, key, value, mask)\n","        \n","        return attn_output, attn_weight\n","\n","class LSTM_attn2(nn.Module):\n","    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers, bidirec = True, dropout = 0):\n","        super(LSTM_attn2, self).__init__()\n","        \n","        self.embed_dim = embed_dim\n","        self.hidden_dim = hidden_dim\n","        self.num_layers = num_layers\n","        self.num_direction = 2 if bidirec else 1\n","        \n","        self.embedding = nn.Embedding(vocab_size, embed_dim)\n","        \n","        self.lstm = nn.LSTM(input_size = embed_dim, hidden_size = hidden_dim,\n","                           num_layers = num_layers, batch_first = True, dropout = dropout,\n","                           bidirectional = bool(bidirec))\n","        \n","        self.lin1 = nn.Linear(hidden_dim * self.num_direction, hidden_dim)\n","        \n","        self.attention = Attention(hidden_dim)\n","        \n","        self.lstm2 = nn.LSTM(input_size = hidden_dim, hidden_size = hidden_dim,\n","                           num_layers = num_layers, batch_first = True, dropout = dropout,\n","                            bidirectional = bool(bidirec))\n","        \n","        self.relu = nn.ReLU()\n","        self.out_lin = nn.Linear(hidden_dim * self.num_direction, 2)\n","    \n","    def subsequent_mask(self, batch, size, loc):\n","        attn_shape = (batch, size, size)\n","#         subsequent_mask = np.triu(np.ones(attn_shape), k = 1).astype('uint8')\n","        subsequent_mask = np.zeros(attn_shape).astype('uint8')\n","    \n","        for i in range(batch):\n","            subsequent_mask[i,:,loc[i]:] = 1\n","\n","        return torch.from_numpy(subsequent_mask) == 0\n","\n","    \n","    def forward(self, x, mask, loc):\n","        embed = self.embedding(x)\n","        h, c = self.init_states(x.size(0), self.num_direction)\n","        \n","        output, (hidden, cell) = self.lstm(embed, (h,c))\n","        output1 = self.lin1(output)\n","                \n","        mask = mask.unsqueeze(-1)\n","        output1 = output1 * mask\n","        \n","        attention_mask = self.subsequent_mask(x.size(0), x.size(1), loc) # batch , seq, mask location\n","        attention_mask = attention_mask.to(device)\n","        \n","        attn_output, attn_weight = self.attention(output1, attention_mask)\n","        \n","        output_attn = attn_output\n","        \n","        output_, (hidden2, cell2) = self.lstm2(output_attn, (hidden, cell))\n","        output_ = self.out_lin(output_)\n","\n","        start = output_[:,:,0]\n","        end = output_[:,:,1]\n","        \n","        return start, end\n","        \n","    def init_states(self, batch_size, num_direction):\n","        return torch.zeros(self.num_layers * num_direction, batch_size, self.hidden_dim).to(device), torch.zeros(self.num_layers * num_direction, batch_size, self.hidden_dim).to(device)\n","        \n","\n","        "],"id":"6d16aef2"},{"cell_type":"code","execution_count":null,"metadata":{"id":"eeb5c87b"},"outputs":[],"source":["from tqdm import tqdm\n","\n","def train(data, model, criterion, optimizer, batch_size = 32, num_iter = 30000, question = False, attention = True):\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","    model.to(device)\n","    model.train()\n","    loss_ = 0.\n","    acc_, start_acc, end_acc, val_score = 0, 0, 0, 0\n","    \n","    for i in tqdm(range(num_iter)):\n","        context, answer_start, answer_end, mask, loc = make_batch(data, batch_size, random = True, question = question)\n","        context, answer_start, answer_end, mask, loc = context.to(device), answer_start.to(device), answer_end.to(device), mask.to(device), loc.to(device)\n","#         context, answer_start, answer_end = context.to(device), answer_start.to(device), answer_end.to(device), #mask.to(device), loc.to(device) ###\n","        \n","        if attention:\n","            start, end = model(context, mask, loc)\n","        else:\n","            start, end = model(context, mask)\n","\n","        \n","        loss_start = criterion(start, answer_start)\n","        loss_end = criterion(end, answer_end-1)\n","        \n","        loss = loss_start/2  + loss_end/2\n","        \n","        model.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # loss\n","        loss_ += loss.detach().cpu()\n","        \n","        # acc\n","        start_acc_ = (start.argmax(dim = -1) == answer_start).detach()\n","        end_acc_ = (end.argmax(dim = -1) == (answer_end -1)).detach()\n","        start_acc += start_acc_.sum().item()*1./batch_size\n","        end_acc += end_acc_.sum().item()*1./batch_size\n","        acc_ += (start_acc_ & end_acc_).sum().item()*1./batch_size\n","                \n","        if i % 1000 == 999 :\n","            print(f'{i + 1 : d}th iters >> loss = {loss_/1000:.4f}, start_acc = {start_acc/1000 * 100 : .4f}, end_acc = {end_acc/1000 * 100 : .4f}, acc = {acc_/1000 * 100 : .4f}')\n","            loss_, start_acc, end_acc, acc_ = 0., 0, 0, 0\n","            with torch.no_grad():\n","                model.eval()\n","                cur_val_score = validation(valid_data, model = model, batch_size = 128, question = question, attention = attention)\n","#                 if attention:\n","#                     if cur_val_score < val_score:\n","#                         optimizer.factor *= 0.8\n","#                 val_score = cur_val_score\n","                model.train()\n","\n","    \n","    return model"],"id":"eeb5c87b"},{"cell_type":"code","execution_count":null,"metadata":{"id":"45945fa9"},"outputs":[],"source":["def validation(data, model, batch_size = 32, question = True, attention = True):\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    predictions = []\n","    references = []\n","\n","\n","    for i in range(len(data)//batch_size):\n","        c, a_s, a_e, m, l= make_batch(data, batch_size = batch_size, index = np.arange(i*batch_size, (i+1)*batch_size), random = False, question = question)\n","        c, a_s, a_e, m, l = c.to(device), a_s.to(device), a_e.to(device), m.to(device), l.to(device)\n","        \n","        if attention:\n","            start, end = model(c,m,l)\n","        else:\n","            start, end = model(c, m) # batch_size * seq_len\n","        \n","        start_index = start.argmax(dim = 1).detach()\n","        end_index = end.argmax(dim = 1).detach()\n","        end_index += 1\n","        \n","        for j in range(batch_size):\n","            if i * batch_size + j in del_valid_data_index:\n","                continue\n","            if start_index[j] >= end_index[j]:\n","                continue\n","            pred, refer = id2word_answer(i * batch_size + j, start_index[j], end_index[j])\n","            predictions.append(pred)\n","            references.append(refer)\n","\n","    results = squad_metric.compute(predictions = predictions, references = references)\n","    print('validation score : ', results)\n","    return results['f1']"],"id":"45945fa9"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36,"referenced_widgets":["3d21288443014edab43081fafbbf5187","9476bbc5710f490ab81d041403efed66","84e28d3611a14eebb6047e13bbb678e2","f033c92a905e4da99e01dbb54a6c0e62","7b75bf356fae42aebb46efd1c09afcbc","9519f328ab7846d89cb2a8013c3db86d","968bcea2dc3d43aba92b662d9b5479cd","9b7b69fdbe6543f1bee0b63c50071b62","a85306d014f041129013fdaeb2ed7a53","4b36aefaf89a4a2cb47f6fbba859c2e6","89586bd2324e493c95be6ac672c1a8ba"]},"executionInfo":{"elapsed":49962,"status":"ok","timestamp":1661010874915,"user":{"displayName":"Andrés Langoyo Martín","userId":"12914381003507187562"},"user_tz":-120},"id":"66da8ddd","outputId":"04166abd-b38d-4c23-c086-bc6077e0bdc9"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:datasets.builder:Reusing dataset squad (/root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"]},{"data":{"application/json":{"ascii":false,"bar_format":null,"colour":null,"elapsed":0.019665241241455078,"initial":0,"n":0,"ncols":null,"nrows":null,"postfix":null,"prefix":"","rate":null,"total":2,"unit":"it","unit_divisor":1000,"unit_scale":false},"application/vnd.jupyter.widget-view+json":{"model_id":"3d21288443014edab43081fafbbf5187","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["squad_dataset = load_dataset('squad')\n","train_data, del_train_data_index, valid_data, del_valid_data_index = preprocessing(squad_dataset)\n","word2id, id2word = make_dict(train_data, del_train_data_index) \n"],"id":"66da8ddd"},{"cell_type":"markdown","metadata":{"id":"BvLJGS4NYHLe"},"source":["```\n","64 42 42 64 64\n","\n","DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'title', 'context', 'question', 'answers'],\n","        num_rows: 87599\n","    })\n","    validation: Dataset({\n","        features: ['id', 'title', 'context', 'question', 'answers'],\n","        num_rows: 10570\n","    })\n","})\n","{'id': '5733be284776f41900661182', 'title': 'University_of_Notre_Dame', 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.', 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?', 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}\n","\n","DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'title', 'context', 'question', 'answers'],\n","        num_rows: 130313\n","    })\n","    validation: Dataset({\n","        features: ['id', 'title', 'context', 'question', 'answers'],\n","        num_rows: 11858\n","    })\n","})\n","{'id': '56be85543aeaaa14008c9063', 'title': 'Beyoncé Knowles', 'context': 'Beyoncé Giselle Knowles-Carter (nacida el 4 de septiembre de 1981) es una cantante, compositora, productora y actriz estadounidense. Nacida y criada en Houston, Texas, actuó en varios concursos de canto y baile cuando era niña, y saltó a la fama a finales de 1990 como cantante del grupo femenino de R & B Destiny \\'s Child. Dirigida por su padre, Mathew Knowles, el grupo se convirtió en uno de los grupos de chicas más vendidos de todos los tiempos. Su hiato vio el lanzamiento del álbum debut de Beyoncé, Dangerously in Love (2003), que la estableció como una artista en solitario en todo el mundo, ganó cinco premios Grammy y presentó el Billboard Hot 100 sencillos número uno \"Crazy in Love\" y \".', 'question': '¿Cuándo Beyonce comenzó a ser popular?', 'answers': {'text': ['a finales de 1990'], 'answer_start': [246]}}\n","\n","64 42 42 64 64\n","\n","\n","```\n","\n","\n","\n"],"id":"BvLJGS4NYHLe"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1661030129341,"user":{"displayName":"Andrés Langoyo Martín","userId":"12914381003507187562"},"user_tz":-120},"id":"20a147b3","outputId":"b6ee8b89-4645-42b4-c8c5-4c60d4a2e20b"},"outputs":[{"name":"stdout","output_type":"stream","text":["79423\n"]}],"source":["vocab_size = len(word2id)\n","embed_dim = 300\n","hidden_dim = 128\n","num_layers = 2\n","bidirec = True, \n","dropout = 0.5\n","print(vocab_size)\n","model = LSTM_attn2(vocab_size=vocab_size,embed_dim=embed_dim,hidden_dim=hidden_dim,num_layers=num_layers,bidirec=bidirec,dropout=dropout)"],"id":"20a147b3"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"3445b1db","outputId":"39455ff5-0a79-4d01-806b-ef44310fe4ad"},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/100000 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  if __name__ == '__main__':\n","  1%|          | 999/100000 [03:10<4:58:55,  5.52it/s]"]},{"name":"stdout","output_type":"stream","text":[" 1000th iters >> loss = 5.3442, start_acc =  2.4156, end_acc =  0.9406, acc =  0.0953\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 1001/100000 [03:32<126:15:54,  4.59s/it]"]},{"name":"stdout","output_type":"stream","text":["validation score :  {'exact_match': 0.16224470318763123, 'f1': 8.134036164487732}\n"]},{"name":"stderr","output_type":"stream","text":["  2%|▏         | 1999/100000 [06:37<4:56:47,  5.50it/s]"]},{"name":"stdout","output_type":"stream","text":[" 2000th iters >> loss = 5.1781, start_acc =  2.5297, end_acc =  1.0469, acc =  0.0453\n"]},{"name":"stderr","output_type":"stream","text":["  2%|▏         | 2001/100000 [06:57<113:22:40,  4.16s/it]"]},{"name":"stdout","output_type":"stream","text":["validation score :  {'exact_match': 0.22905134567665586, 'f1': 8.00265522159278}\n"]},{"name":"stderr","output_type":"stream","text":["  3%|▎         | 2999/100000 [10:02<4:58:32,  5.42it/s]"]},{"name":"stdout","output_type":"stream","text":[" 3000th iters >> loss = 5.1694, start_acc =  2.3781, end_acc =  1.2297, acc =  0.1453\n"]},{"name":"stderr","output_type":"stream","text":["\r  3%|▎         | 3000/100000 [10:17<122:57:00,  4.56s/it]"]},{"name":"stdout","output_type":"stream","text":["validation score :  {'exact_match': 0.9925558312655087, 'f1': 4.426553248205472}\n"]},{"name":"stderr","output_type":"stream","text":["  4%|▍         | 3999/100000 [13:22<4:59:21,  5.34it/s]"]},{"name":"stdout","output_type":"stream","text":[" 4000th iters >> loss = 5.6175, start_acc =  2.5547, end_acc =  0.7750, acc =  0.4516\n"]},{"name":"stderr","output_type":"stream","text":["  4%|▍         | 4001/100000 [13:36<86:12:22,  3.23s/it] "]},{"name":"stdout","output_type":"stream","text":["validation score :  {'exact_match': 1.0020996373353694, 'f1': 2.536275709903091}\n"]},{"name":"stderr","output_type":"stream","text":["  5%|▍         | 4999/100000 [16:40<4:42:00,  5.61it/s]"]},{"name":"stdout","output_type":"stream","text":[" 5000th iters >> loss = 5.5415, start_acc =  2.5625, end_acc =  0.8297, acc =  0.3687\n"]},{"name":"stderr","output_type":"stream","text":["  5%|▌         | 5001/100000 [16:56<89:14:08,  3.38s/it] "]},{"name":"stdout","output_type":"stream","text":["validation score :  {'exact_match': 1.1261691162435579, 'f1': 4.084475020716757}\n"]},{"name":"stderr","output_type":"stream","text":["  6%|▌         | 5999/100000 [20:03<4:45:53,  5.48it/s]"]},{"name":"stdout","output_type":"stream","text":[" 6000th iters >> loss = 5.2578, start_acc =  2.5203, end_acc =  0.9469, acc =  0.1703\n"]},{"name":"stderr","output_type":"stream","text":["  6%|▌         | 6001/100000 [20:19<91:55:28,  3.52s/it] "]},{"name":"stdout","output_type":"stream","text":["validation score :  {'exact_match': 1.1070815041038367, 'f1': 5.714539018853245}\n"]},{"name":"stderr","output_type":"stream","text":["  7%|▋         | 6999/100000 [23:25<5:18:25,  4.87it/s]"]},{"name":"stdout","output_type":"stream","text":[" 7000th iters >> loss = 5.1771, start_acc =  2.8469, end_acc =  1.0578, acc =  0.2266\n"]},{"name":"stderr","output_type":"stream","text":["  7%|▋         | 7001/100000 [23:45<113:25:17,  4.39s/it]"]},{"name":"stdout","output_type":"stream","text":["validation score :  {'exact_match': 0.8016797098682955, 'f1': 7.878946565794727}\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 7999/100000 [26:52<4:30:22,  5.67it/s]"]},{"name":"stdout","output_type":"stream","text":[" 8000th iters >> loss = 5.1770, start_acc =  3.0437, end_acc =  1.1594, acc =  0.3000\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 8001/100000 [27:11<103:31:03,  4.05s/it]"]},{"name":"stdout","output_type":"stream","text":["validation score :  {'exact_match': 0.4581026913533117, 'f1': 7.954753757937509}\n"]},{"name":"stderr","output_type":"stream","text":["  9%|▉         | 8999/100000 [30:17<4:38:13,  5.45it/s]"]},{"name":"stdout","output_type":"stream","text":[" 9000th iters >> loss = 5.1611, start_acc =  3.2422, end_acc =  1.2688, acc =  0.4625\n"]},{"name":"stderr","output_type":"stream","text":["  9%|▉         | 9001/100000 [30:34<90:58:33,  3.60s/it] "]},{"name":"stdout","output_type":"stream","text":["validation score :  {'exact_match': 1.409443269908386, 'f1': 7.557691635013675}\n"]},{"name":"stderr","output_type":"stream","text":[" 10%|▉         | 9999/100000 [33:39<4:54:10,  5.10it/s]"]},{"name":"stdout","output_type":"stream","text":[" 10000th iters >> loss = 5.3613, start_acc =  3.3125, end_acc =  1.2453, acc =  0.6234\n"]},{"name":"stderr","output_type":"stream","text":["\r 10%|█         | 10000/100000 [33:54<111:23:51,  4.46s/it]"]},{"name":"stdout","output_type":"stream","text":["validation score :  {'exact_match': 1.8419545714831074, 'f1': 4.505984806205697}\n"]},{"name":"stderr","output_type":"stream","text":[" 11%|█         | 10999/100000 [36:59<4:22:06,  5.66it/s]"]},{"name":"stdout","output_type":"stream","text":[" 11000th iters >> loss = 5.8137, start_acc =  3.1719, end_acc =  0.9437, acc =  0.7063\n"]},{"name":"stderr","output_type":"stream","text":[" 11%|█         | 11001/100000 [37:14<81:43:10,  3.31s/it] "]},{"name":"stdout","output_type":"stream","text":["validation score :  {'exact_match': 1.2597824012216072, 'f1': 3.7013600821344346}\n"]},{"name":"stderr","output_type":"stream","text":[" 12%|█▏        | 11999/100000 [40:18<4:29:22,  5.44it/s]"]},{"name":"stdout","output_type":"stream","text":[" 12000th iters >> loss = 5.3477, start_acc =  3.1906, end_acc =  1.2297, acc =  0.6313\n"]},{"name":"stderr","output_type":"stream","text":[" 12%|█▏        | 12001/100000 [40:36<97:14:28,  3.98s/it] "]},{"name":"stdout","output_type":"stream","text":["validation score :  {'exact_match': 1.1836578846888126, 'f1': 7.33046652806769}\n"]},{"name":"stderr","output_type":"stream","text":[" 13%|█▎        | 12999/100000 [43:40<4:03:09,  5.96it/s]"]},{"name":"stdout","output_type":"stream","text":[" 13000th iters >> loss = 5.1545, start_acc =  3.4250, end_acc =  1.4000, acc =  0.6000\n"]},{"name":"stderr","output_type":"stream","text":["\r 13%|█▎        | 13000/100000 [43:59<144:03:35,  5.96s/it]"]},{"name":"stdout","output_type":"stream","text":["validation score :  {'exact_match': 1.1166253101736974, 'f1': 7.981233810872179}\n"]},{"name":"stderr","output_type":"stream","text":[" 14%|█▍        | 13999/100000 [47:03<3:50:26,  6.22it/s]"]},{"name":"stdout","output_type":"stream","text":[" 14000th iters >> loss = 5.1433, start_acc =  3.4594, end_acc =  1.4500, acc =  0.6594\n"]},{"name":"stderr","output_type":"stream","text":[" 14%|█▍        | 14001/100000 [47:24<108:50:37,  4.56s/it]"]},{"name":"stdout","output_type":"stream","text":["validation score :  {'exact_match': 1.3463191062732742, 'f1': 7.94274578860392}\n"]},{"name":"stderr","output_type":"stream","text":[" 15%|█▍        | 14999/100000 [50:24<4:17:21,  5.50it/s]"]},{"name":"stdout","output_type":"stream","text":[" 15000th iters >> loss = 5.1296, start_acc =  3.5203, end_acc =  1.5922, acc =  0.7828\n"]},{"name":"stderr","output_type":"stream","text":[" 15%|█▌        | 15001/100000 [50:43<95:13:34,  4.03s/it] "]},{"name":"stdout","output_type":"stream","text":["validation score :  {'exact_match': 1.3268423062237495, 'f1': 8.122414196493267}\n"]},{"name":"stderr","output_type":"stream","text":[" 16%|█▌        | 15999/100000 [53:48<4:12:26,  5.55it/s]"]},{"name":"stdout","output_type":"stream","text":[" 16000th iters >> loss = 5.1104, start_acc =  3.6953, end_acc =  1.6438, acc =  0.8953\n"]},{"name":"stderr","output_type":"stream","text":["\r 16%|█▌        | 16000/100000 [54:05<127:30:17,  5.46s/it]"]},{"name":"stdout","output_type":"stream","text":["validation score :  {'exact_match': 1.431570910479099, 'f1': 7.620834366125876}\n"]},{"name":"stderr","output_type":"stream","text":[" 17%|█▋        | 16999/100000 [57:14<4:26:35,  5.19it/s]"]},{"name":"stdout","output_type":"stream","text":[" 17000th iters >> loss = 5.1069, start_acc =  3.5312, end_acc =  1.6578, acc =  0.8563\n"]},{"name":"stderr","output_type":"stream","text":[" 17%|█▋        | 17001/100000 [57:31<85:58:00,  3.73s/it] "]},{"name":"stdout","output_type":"stream","text":["validation score :  {'exact_match': 1.6973532796317607, 'f1': 7.092565431199872}\n"]},{"name":"stderr","output_type":"stream","text":[" 18%|█▊        | 17999/100000 [1:00:34<4:04:39,  5.59it/s]"]},{"name":"stdout","output_type":"stream","text":[" 18000th iters >> loss = 5.0895, start_acc =  3.7047, end_acc =  1.6953, acc =  0.8672\n"]},{"name":"stderr","output_type":"stream","text":[" 18%|█▊        | 18001/100000 [1:00:51<86:44:19,  3.81s/it] "]},{"name":"stdout","output_type":"stream","text":["validation score :  {'exact_match': 1.3559969442322384, 'f1': 6.72776697832015}\n"]},{"name":"stderr","output_type":"stream","text":[" 19%|█▉        | 18999/100000 [1:03:55<4:13:09,  5.33it/s]"]},{"name":"stdout","output_type":"stream","text":[" 19000th iters >> loss = 5.0851, start_acc =  3.5453, end_acc =  1.5859, acc =  0.8328\n"]},{"name":"stderr","output_type":"stream","text":["\r 19%|█▉        | 19000/100000 [1:04:16<140:16:58,  6.23s/it]"]},{"name":"stdout","output_type":"stream","text":["validation score :  {'exact_match': 1.4398917665249324, 'f1': 7.061806601505108}\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|█▉        | 19999/100000 [1:07:18<3:50:40,  5.78it/s]"]},{"name":"stdout","output_type":"stream","text":[" 20000th iters >> loss = 5.0732, start_acc =  3.5781, end_acc =  1.8453, acc =  0.9531\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 20001/100000 [1:07:36<86:35:34,  3.90s/it] "]},{"name":"stdout","output_type":"stream","text":["validation score :  {'exact_match': 1.5845742649866361, 'f1': 7.255931865485115}\n"]},{"name":"stderr","output_type":"stream","text":[" 21%|██        | 20999/100000 [1:10:41<4:22:12,  5.02it/s]"]},{"name":"stdout","output_type":"stream","text":[" 21000th iters >> loss = 5.0678, start_acc =  3.6328, end_acc =  1.8344, acc =  0.9562\n"]},{"name":"stderr","output_type":"stream","text":["\r 21%|██        | 21000/100000 [1:11:00<129:20:52,  5.89s/it]"]},{"name":"stdout","output_type":"stream","text":["validation score :  {'exact_match': 1.5970163526824137, 'f1': 7.4635950301297305}\n"]},{"name":"stderr","output_type":"stream","text":[" 22%|██▏       | 21999/100000 [1:14:06<4:00:20,  5.41it/s]"]},{"name":"stdout","output_type":"stream","text":[" 22000th iters >> loss = 5.0666, start_acc =  3.6266, end_acc =  1.9109, acc =  0.9969\n"]},{"name":"stderr","output_type":"stream","text":[" 22%|██▏       | 22001/100000 [1:14:25<88:21:55,  4.08s/it] "]},{"name":"stdout","output_type":"stream","text":["validation score :  {'exact_match': 1.4046822742474916, 'f1': 7.45348594916678}\n"]},{"name":"stderr","output_type":"stream","text":[" 23%|██▎       | 22999/100000 [1:17:27<4:09:48,  5.14it/s]"]},{"name":"stdout","output_type":"stream","text":[" 23000th iters >> loss = 5.0491, start_acc =  3.6969, end_acc =  1.8734, acc =  0.9750\n"]},{"name":"stderr","output_type":"stream","text":[" 23%|██▎       | 23001/100000 [1:17:49<102:00:48,  4.77s/it]"]},{"name":"stdout","output_type":"stream","text":["validation score :  {'exact_match': 1.0651568947317915, 'f1': 7.840213135749772}\n"]},{"name":"stderr","output_type":"stream","text":[" 24%|██▍       | 23999/100000 [1:20:51<4:01:08,  5.25it/s]"]},{"name":"stdout","output_type":"stream","text":[" 24000th iters >> loss = 5.0355, start_acc =  3.7391, end_acc =  1.8672, acc =  0.9609\n"]},{"name":"stderr","output_type":"stream","text":[" 24%|██▍       | 24001/100000 [1:21:11<87:46:51,  4.16s/it] "]},{"name":"stdout","output_type":"stream","text":["validation score :  {'exact_match': 1.4011015557058653, 'f1': 7.763614838512975}\n"]},{"name":"stderr","output_type":"stream","text":[" 25%|██▍       | 24999/100000 [1:24:13<3:58:51,  5.23it/s]"]},{"name":"stdout","output_type":"stream","text":[" 25000th iters >> loss = 5.0288, start_acc =  3.7812, end_acc =  1.9297, acc =  1.0453\n"]},{"name":"stderr","output_type":"stream","text":[" 25%|██▌       | 25001/100000 [1:24:32<86:53:27,  4.17s/it] "]},{"name":"stdout","output_type":"stream","text":["validation score :  {'exact_match': 1.34696217042415, 'f1': 7.622625589356721}\n"]},{"name":"stderr","output_type":"stream","text":[" 26%|██▌       | 25999/100000 [1:27:35<3:46:51,  5.44it/s]"]},{"name":"stdout","output_type":"stream","text":[" 26000th iters >> loss = 5.0210, start_acc =  3.6984, end_acc =  1.9375, acc =  0.9984\n"]},{"name":"stderr","output_type":"stream","text":[" 26%|██▌       | 26001/100000 [1:27:54<83:39:13,  4.07s/it] "]},{"name":"stdout","output_type":"stream","text":["validation score :  {'exact_match': 1.3179571663920921, 'f1': 6.930406918806188}\n"]},{"name":"stderr","output_type":"stream","text":[" 27%|██▋       | 26694/100000 [1:30:02<3:47:23,  5.37it/s]"]}],"source":["criterion=nn.CrossEntropyLoss()\n","learning_rate=0.5\n","optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)\n","train(train_data, model, criterion, optimizer, batch_size = 64, num_iter = 100000, question = True, attention = True)"],"id":"3445b1db"},{"cell_type":"code","execution_count":null,"metadata":{"id":"BuKKC3Llw1mX"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('./montura')"],"id":"BuKKC3Llw1mX"},{"cell_type":"markdown","metadata":{"id":"FBdEZk3rzspj"},"source":["Code to save things and predict"],"id":"FBdEZk3rzspj"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ACOiF0nn1leA"},"outputs":[],"source":["def predict(data, model, batch_size = 1, question = True):\n","    device = 'cpu' if torch.cuda.is_available() else 'cpu'\n","    predictions = []\n","    references = []\n","\n","\n","    for i in range(len(data)//batch_size):\n","        c, a_s, a_e, m, l= make_batch(data, batch_size = batch_size, index = np.arange(i*batch_size, (i+1)*batch_size), random = False, question = question)        \n","        \n","        start, end = model(c,m,l)\n","  \n","        \n","        start_index = start.argmax(dim = 1).detach()\n","        end_index = end.argmax(dim = 1).detach()\n","        end_index += 1\n","        \n","        for j in range(batch_size):\n","            if i * batch_size + j in del_valid_data_index:\n","                continue\n","            if start_index[j] >= end_index[j]:\n","                continue\n","            pred, refer = id2word_answer(i * batch_size + j, start_index[j], end_index[j])\n","            predictions.append(pred)\n","            references.append(refer)\n","    return predictions"],"id":"ACOiF0nn1leA"},{"cell_type":"code","execution_count":null,"metadata":{"id":"kdx1CJh7ya0V"},"outputs":[],"source":[" import pickle\n"," class Library():\n","    def assign(self,word2id,id2word):\n","        self.word2id = word2id\n","        self.id2word = id2word\n","    def save(self):\n","        \"\"\"save class as self.name.txt\"\"\"\n","        file = open('./montura/MyDrive/TFG/lstm_data.txt','wb')\n","        file.write(pickle.dumps(self.__dict__))\n","        file.close()\n","\n","    def load(self):\n","        \"\"\"try load self.name.txt\"\"\"\n","        file = open('./montura/MyDrive/TFG/lstm_data.txt','rb')\n","        dataPickle = file.read()\n","        file.close()\n","\n","        self.__dict__ = pickle.loads(dataPickle)"],"id":"kdx1CJh7ya0V"},{"cell_type":"code","execution_count":null,"metadata":{"id":"dJsL-S70zMTb"},"outputs":[],"source":["library = Library()\n","library.assign(word2id,id2word)\n","library.save()"],"id":"dJsL-S70zMTb"},{"cell_type":"code","execution_count":null,"metadata":{"id":"nIeQM1zMvfjm"},"outputs":[],"source":["torch.save(model.state_dict(), './montura/MyDrive/TFG/lstm_model')\n"],"id":"nIeQM1zMvfjm"},{"cell_type":"code","execution_count":null,"metadata":{"id":"vKAs-N1c1PbG"},"outputs":[],"source":["library = Library()\n","library.load()"],"id":"vKAs-N1c1PbG"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q52Fbtkn3aNP"},"outputs":[],"source":["question = 'When the three types of rock are re-melted what is formed?'\n","context = 'There are three major types of rock: igneous, sedimentary, and metamorphic. The rock cycle is an important concept in geology which illustrates the relationships between these three types of rock, and magma. When a rock crystallizes from melt (magma and/or lava), it is an igneous rock. This rock can be weathered and eroded, and then redeposited and lithified into a sedimentary rock, or be turned into a metamorphic rock due to heat and pressure that change the mineral content of the rock which gives it a characteristic fabric. The sedimentary rock can then be subsequently turned into a metamorphic rock due to heat and pressure and is then weathered, eroded, deposited, and lithified, ultimately becoming a sedimentary rock. Sedimentary rock may also be re-eroded and redeposited, and metamorphic rock may also undergo additional metamorphism. All three types of rocks may be re-melted; when this happens, a new magma is formed, from which an igneous rock may once again crystallize.'"],"id":"Q52Fbtkn3aNP"},{"cell_type":"code","execution_count":null,"metadata":{"id":"jT9qm25Y2rus"},"outputs":[],"source":["data = {\n","    'train':{\n","        'id':[''],\n","        'title':[''],\n","        'answer':[''],\n","        'question':[''],\n","        'context':['']\n","    },\n","    'validation':{\n","        'id':[''],\n","        'title':[''],\n","        'answer':[''],\n","        'question':[question],\n","        'context':[context]\n","    }\n","}\n","train_data, del_train_data_index, valid_data, del_valid_data_index = preprocessing(data)\n","print(train_data, del_train_data_index, valid_data, del_valid_data_index)\n"],"id":"jT9qm25Y2rus"},{"cell_type":"code","execution_count":null,"metadata":{"id":"E-6XyPUgwp26"},"outputs":[],"source":["vocab_size = len(library.word2id)\n","embed_dim = 300\n","hidden_dim = 128\n","num_layers = 2\n","bidirec = True, \n","dropout = 0.5\n","model = LSTM_attn2(vocab_size=vocab_size,embed_dim=embed_dim,hidden_dim=hidden_dim,num_layers=num_layers,bidirec=bidirec,dropout=dropout)\n","model.load_state_dict(torch.load('./montura/MyDrive/TFG/lstm_model'))\n","model.eval()"],"id":"E-6XyPUgwp26"},{"cell_type":"code","execution_count":null,"metadata":{"id":"pkpMPmz-Xrxi"},"outputs":[],"source":[],"id":"pkpMPmz-Xrxi"},{"cell_type":"code","execution_count":null,"metadata":{"id":"juB64sUcUSni"},"outputs":[],"source":["results = predict(valid_data,model)\n","results"],"id":"juB64sUcUSni"}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.5 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"},"vscode":{"interpreter":{"hash":"8abf625e542ff33194dd4502f291ce11b7bf8daed732e6d5f31b5a030b27ce17"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"112db4ff649d4754b6294c92a0139b5a":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_61df97bc3f424116b65267dec26025a3","max":1119,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c9505fe6cd6749c78d3ffd19a229085c","tabbable":null,"tooltip":null,"value":1119}},"14b1614325784435a3d92346abf9a732":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c81ef08e3255462796d628a7b4353fd5","IPY_MODEL_4e66d7661f094e5b93c63896f767e6eb","IPY_MODEL_67fe51f221994db5bf850e6d00078dab"],"layout":"IPY_MODEL_c2407428f34d4af0a2e65cd2836e1add","tabbable":null,"tooltip":null}},"2d63d6d48d9f48e4947ec386468c0b7c":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34aa7831b12647919744d4cf3e9114bd":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d21288443014edab43081fafbbf5187":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9476bbc5710f490ab81d041403efed66","IPY_MODEL_84e28d3611a14eebb6047e13bbb678e2","IPY_MODEL_f033c92a905e4da99e01dbb54a6c0e62"],"layout":"IPY_MODEL_7b75bf356fae42aebb46efd1c09afcbc","tabbable":null,"tooltip":null}},"45710764b4354e27a12cae622a68e660":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4b36aefaf89a4a2cb47f6fbba859c2e6":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e66d7661f094e5b93c63896f767e6eb":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_c59f461d2bf1483997e7e30354651810","max":1715,"min":0,"orientation":"horizontal","style":"IPY_MODEL_45710764b4354e27a12cae622a68e660","tabbable":null,"tooltip":null,"value":1715}},"59ca87c8533d4999962fab467057d16a":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"5de5081627914f06bcf4a09459fbff97":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_2d63d6d48d9f48e4947ec386468c0b7c","placeholder":"​","style":"IPY_MODEL_b1c428dbd7f14c94bf890b73c7b051ad","tabbable":null,"tooltip":null,"value":" 3.31k/? [00:00&lt;00:00, 106kB/s]"}},"61df97bc3f424116b65267dec26025a3":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67fe51f221994db5bf850e6d00078dab":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_8e99850fc8f24225bc0837e31eb427a7","placeholder":"​","style":"IPY_MODEL_59ca87c8533d4999962fab467057d16a","tabbable":null,"tooltip":null,"value":" 4.50k/? [00:00&lt;00:00, 132kB/s]"}},"7b75bf356fae42aebb46efd1c09afcbc":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84e28d3611a14eebb6047e13bbb678e2":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_9b7b69fdbe6543f1bee0b63c50071b62","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a85306d014f041129013fdaeb2ed7a53","tabbable":null,"tooltip":null,"value":2}},"85a555b973e14d6eb928a73e90905bb0":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89586bd2324e493c95be6ac672c1a8ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"8e99850fc8f24225bc0837e31eb427a7":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90d8307121164fddb2a3742e43d0acd2":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"9476bbc5710f490ab81d041403efed66":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_9519f328ab7846d89cb2a8013c3db86d","placeholder":"​","style":"IPY_MODEL_968bcea2dc3d43aba92b662d9b5479cd","tabbable":null,"tooltip":null,"value":"100%"}},"9519f328ab7846d89cb2a8013c3db86d":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"968bcea2dc3d43aba92b662d9b5479cd":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"9b7b69fdbe6543f1bee0b63c50071b62":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a85306d014f041129013fdaeb2ed7a53":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b1c428dbd7f14c94bf890b73c7b051ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"c2407428f34d4af0a2e65cd2836e1add":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c59f461d2bf1483997e7e30354651810":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c81ef08e3255462796d628a7b4353fd5":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_d56fcbc1046249cbb84963a241491232","placeholder":"​","style":"IPY_MODEL_fa9d8a79d15a483881a8c16ab6edb32d","tabbable":null,"tooltip":null,"value":"Downloading builder script: "}},"c9505fe6cd6749c78d3ffd19a229085c":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d56fcbc1046249cbb84963a241491232":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dbe44fde2789492686680796ed70a311":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eb901f9492834794a87869183e8d7b3d","IPY_MODEL_112db4ff649d4754b6294c92a0139b5a","IPY_MODEL_5de5081627914f06bcf4a09459fbff97"],"layout":"IPY_MODEL_85a555b973e14d6eb928a73e90905bb0","tabbable":null,"tooltip":null}},"eb901f9492834794a87869183e8d7b3d":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_34aa7831b12647919744d4cf3e9114bd","placeholder":"​","style":"IPY_MODEL_90d8307121164fddb2a3742e43d0acd2","tabbable":null,"tooltip":null,"value":"Downloading extra modules: "}},"f033c92a905e4da99e01dbb54a6c0e62":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_4b36aefaf89a4a2cb47f6fbba859c2e6","placeholder":"​","style":"IPY_MODEL_89586bd2324e493c95be6ac672c1a8ba","tabbable":null,"tooltip":null,"value":" 2/2 [00:00&lt;00:00, 42.14it/s]"}},"fa9d8a79d15a483881a8c16ab6edb32d":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}}}}},"nbformat":4,"nbformat_minor":5}